import os
import json
import numpy as np
import cv2
from paddleocr import PaddleOCR
from difflib import SequenceMatcher

# åˆå§‹åŒ–OCRæ¨¡å‹
ocr = PaddleOCR(rec_model_dir='/root/workspace/paddle/inference/P-OCRv4_server_rec', use_angle_cls=True, use_gpu=True)

def calculate_accuracy(pred_text, gt_text):
    """è®¡ç®—Levenshteinè·ç¦»çš„å­—ç¬¦åŒ¹é…ç²¾åº¦"""
    matcher = SequenceMatcher(None, pred_text, gt_text)
    return matcher.ratio()

def evaluate_ocr(image_folder, gt_txt, output_json="ocr_results.json"):
    """è¯„ä¼°OCRæ¨¡å‹åœ¨æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„è¯†åˆ«ç²¾åº¦ï¼Œå¹¶ä¿å­˜ç»“æœä¸ºJSON"""
    
    print("\n========== [1] è¯»å– Ground Truth ========== ")
    gt_dict = {}
    try:
        with open(gt_txt, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split('	')  # å‡è®¾æ ¼å¼ï¼šfilename textï¼ˆç©ºæ ¼åˆ†éš”ï¼‰
                if len(parts) >= 2:
                    filename = parts[0].strip()
                    gt_text = ' '.join(parts[1:]).strip()
                    gt_dict[filename] = gt_text
        print(f"æˆåŠŸè¯»å– Ground Truthï¼Œå…± {len(gt_dict)} æ¡è®°å½•")
    except Exception as e:
        print(f"é”™è¯¯ï¼šæ— æ³•è¯»å– ground truth æ–‡ä»¶ - {str(e)}")
        return

    print("\n========== [2] æ£€æŸ¥å›¾åƒæ–‡ä»¶å¤¹ ========== ")
    if not os.path.exists(image_folder):
        print(f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ {image_folder} ä¸å­˜åœ¨ï¼")
        return
    
    image_files = os.listdir(image_folder)
    if not image_files:
        print("é”™è¯¯ï¼šå›¾ç‰‡æ–‡ä»¶å¤¹ä¸ºç©ºï¼")
        return
    print(f"å‘ç° {len(image_files)} å¼ å›¾ç‰‡")

    results_list = []
    accuracies = []

    print("\n========== [3] å¼€å§‹OCRè¯†åˆ« ========== ")
    images_found = False  # æ ‡å¿—æ˜¯å¦æœ‰æœ‰æ•ˆå›¾ç‰‡

    for image_name in image_files:
        image_path = os.path.join(image_folder, image_name)
        
        print(f"\n>>> å¤„ç†å›¾ç‰‡: {image_name}")
        
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å¯ä»¥åŠ è½½
        img = cv2.imread(image_path)
        if img is None:
            print(f"è­¦å‘Šï¼šæ— æ³•è½½å…¥ {image_name}ï¼Œå¯èƒ½æ˜¯æ— æ•ˆå›¾åƒæˆ–è·¯å¾„é”™è¯¯")
            continue
        print("âœ… å›¾ç‰‡è½½å…¥æˆåŠŸ")

        # æ£€æŸ¥ ground truth æ˜¯å¦å­˜åœ¨
        if image_name not in gt_dict:
            print(f"âš ï¸ è­¦å‘Šï¼š{image_name} æ²¡æœ‰å¯¹åº”çš„ground truthï¼Œè·³è¿‡ï¼")
            continue
        
        images_found = True
        gt_text = gt_dict[image_name]
        print(f"Ground Truth: {gt_text}")

        # è¿è¡Œ OCR è¯†åˆ«
        result = ocr.ocr(image_path, cls=True)
        
        if not result or not result[0]:
            print(f"âš ï¸ è­¦å‘Šï¼š{image_name} OCR ç»“æœä¸ºç©º")
            pred_text = ""
        else:
            pred_text = ''.join([res[1][0] for res in result[0]])
        
        print(f"OCR è¯†åˆ«ç»“æœ: {pred_text}")

        acc = calculate_accuracy(pred_text, gt_text)
        accuracies.append(acc)

        # å­˜å…¥ JSON ç»“æœ
        results_list.append({
            "image": image_name,
            "predicted_text": pred_text,
            "ground_truth": gt_text,
            "accuracy": round(acc, 4)
        })

        print(f"âœ… è®¡ç®—ç²¾åº¦: {acc:.4f}")

    print("\n========== [4] è®¡ç®—æœ€ç»ˆå‡†ç¡®ç‡ ========== ")
    if accuracies:  # ç¡®ä¿éç©º
        avg_acc = np.mean(accuracies)
        std_acc = np.std(accuracies)
    else:
        avg_acc = 0
        std_acc = 0
        print("âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰å¯ç”¨çš„ OCR ç»“æœï¼Œå¹³å‡å‡†ç¡®ç‡å’Œæ ‡å‡†å·®è®¾ä¸º 0")

    print(f"\nğŸ“Š å¹³å‡å‡†ç¡®ç‡: {avg_acc:.4f}")
    print(f"ğŸ“Š æ ‡å‡†å·®: {std_acc:.4f}")

    # ä¿å­˜ JSON ç»“æœ
    with open(output_json, "w", encoding="utf-8") as json_file:
        json.dump({
            "average_accuracy": round(avg_acc, 4),
            "std_accuracy": round(std_acc, 4),
            "results": results_list
        }, json_file, ensure_ascii=False, indent=4)

    print(f"\nâœ… OCR ç»“æœå·²ä¿å­˜åˆ° {output_json}")

# è®¾ç½®è·¯å¾„
evaluate_ocr('/root/workspace/paddle/data/train_data/rec/train', '/root/workspace/paddle/data/train_data/rec/rec_gt_train.txt')
